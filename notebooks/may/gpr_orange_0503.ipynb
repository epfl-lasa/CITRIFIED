{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, Matern, WhiteKernel\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = 4000\n",
    "test_size = 0.3\n",
    "nb_test_points = round(dataset_size * test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = loadmat('../mat_files/orange_straight_0503.mat')\n",
    "data = mat['straight_cuts'][0]\n",
    "train_set, test_set = train_test_split(data, test_size=test_size, random_state=42)\n",
    "\n",
    "downsampled_train_set = []\n",
    "for i in range(len(train_set)):\n",
    "    tmp = resample(train_set[i], n_samples=round((dataset_size-nb_test_points)/len(train_set)), replace=False, random_state=42)\n",
    "    downsampled_train_set.append(tmp)\n",
    "\n",
    "downsampled_test_set = []    \n",
    "for i in range(len(test_set)):\n",
    "    tmp = resample(test_set[i], n_samples=round(nb_test_points/len(test_set)), replace=False, random_state=42)\n",
    "    downsampled_test_set.append(tmp)\n",
    "\n",
    "#print(downsampled_train_set)\n",
    "\n",
    "downsampled_train_set = np.concatenate(downsampled_train_set, axis=0)\n",
    "downsampled_train_set = np.delete(downsampled_train_set,np.where(downsampled_train_set[:,1] < 0.009), axis=0)\n",
    "#downsampled_train_set[:,2] = [10*x for x in downsampled_train_set[:,2]]\n",
    "X_train = downsampled_train_set[:,2:4]\n",
    "y_train = downsampled_train_set[:,4].reshape(-1, 1)\n",
    "#print(X_train)\n",
    "#print(y_train)\n",
    "downsampled_test_set = np.concatenate(downsampled_test_set, axis=0)\n",
    "downsampled_train_set = np.delete(downsampled_train_set,np.where(downsampled_train_set[:,1] < 0.009), axis=0)\n",
    "#downsampled_test_set[:,2] = [10*x for x in downsampled_test_set[:,2]]\n",
    "X_test = downsampled_test_set[:,2:4]\n",
    "y_test = downsampled_test_set[:,4].reshape(-1, 1)\n",
    "#X[:,0] = [-10*x for x in X[:,0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "y_train_norm =scaler.fit_transform(y_train)\n",
    "y_test_norm = scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kernel = RBF([8.02e-05, 0.0012], length_scale_bounds='fixed') + WhiteKernel(0.0458, noise_level_bounds='fixed') # 2000, 0.3, aniso\n",
    "kernel = RBF([0.0015, 0.003], length_scale_bounds='fixed') + WhiteKernel(0.3, noise_level_bounds='fixed') # 2000, 0.3\n",
    "#kernel = RBF([0.01, 0.01]) + WhiteKernel()\n",
    "gpr = GaussianProcessRegressor(kernel=kernel,\n",
    "                               normalize_y=False,\n",
    "                               n_restarts_optimizer=10,\n",
    "                               random_state=42)\n",
    "gpr.fit(X_train, y_train_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rbf_orange_0503.pickle', 'wb') as f:\n",
    "    pickle.dump({'gpr': gpr, 'scaler': scaler}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kernel = Matern([0.00312, 0.00363], length_scale_bounds='fixed', nu=1.5) + WhiteKernel(0.0307, noise_level_bounds='fixed') # 2000, 0.3, aniso\n",
    "kernel = Matern([0.02, 0.01], length_scale_bounds='fixed', nu=1.5) + WhiteKernel(0.01, noise_level_bounds='fixed') # 2000, 0.3, aniso\n",
    "#kernel = Matern([0.01, 0.01], nu=1.5) + WhiteKernel()\n",
    "gpr = GaussianProcessRegressor(kernel=kernel,\n",
    "                               normalize_y=False,\n",
    "                               n_restarts_optimizer=10,\n",
    "                               random_state=42)\n",
    "gpr.fit(X_train, y_train_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kernel = Matern([0.00246, 0.00287], length_scale_bounds='fixed', nu=2.5) + WhiteKernel(0.0369, noise_level_bounds='fixed') # 2000, 0.3, aniso\n",
    "kernel = Matern([0.025, 0.015], length_scale_bounds='fixed', nu=2.5) + WhiteKernel(0.01, noise_level_bounds='fixed') # 2000, 0.3, aniso\n",
    "#kernel = Matern([0.01, 0.01], nu=2.5) + WhiteKernel()\n",
    "gpr = GaussianProcessRegressor(kernel=kernel,\n",
    "                               normalize_y=False,\n",
    "                               n_restarts_optimizer=10,\n",
    "                               random_state=42)\n",
    "gpr.fit(X_train, y_train_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(gpr.get_params())\n",
    "print(gpr.kernel_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X1, X2 = np.meshgrid(np.linspace(np.min(X_train[:,0]),np.max(X_train[:,0]),100),np.linspace(np.min(X_train[:,1]),np.max(X_train[:,1]),100))\n",
    "Y = np.zeros((100,100))\n",
    "#Y_upper = np.zeros((100,100))\n",
    "#Y_lower = np.zeros((100,100))\n",
    "std_mesh = np.zeros((100,100))\n",
    "for i in range(100):\n",
    "    for j in range(100):\n",
    "        res, std = gpr.predict(np.array([X1[i,j], X2[i,j]]).reshape(1,-1), return_std=True)\n",
    "        Y[i,j] = scaler.inverse_transform(res)\n",
    "        #Y_upper[i,j] = Y[i,j] + 2*np.sqrt(std) * scaler.scale_\n",
    "        #Y_lower[i,j] = Y[i,j] - 2*np.sqrt(std) * scaler.scale_\n",
    "        std_mesh[i,j] = 2 * std * scaler.scale_\n",
    "\n",
    "Y_upper = Y + std_mesh\n",
    "Y_lower = Y - std_mesh\n",
    "        \n",
    "        \n",
    "#X1, X2 = np.meshgrid(np.sort(X_test[:,0]), np.sort(X_test[:,1]))\n",
    "#Y = np.zeros(X1.shape)\n",
    "#Y_upper = np.zeros(X1.shape)\n",
    "#Y_lower = np.zeros(X1.shape)\n",
    "#for i in range(Y.shape[0]):\n",
    "#    for j in range(Y.shape[1]):\n",
    "#        res, std = gpr.predict(np.array([X1[i,j], X2[i,j]]).reshape(1,-1), return_std=True)\n",
    "#        Y[i,j] = scaler.inverse_transform(res)\n",
    "#        Y_upper[i,j] = Y[i,j] + 2*np.sqrt(std) * scaler.scale_\n",
    "#        Y_lower[i,j] = Y[i,j] - 2*np.sqrt(std) * scaler.scale_\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Surface(z=Y, x=X1, y=X2, cmax=np.max(Y_upper), cmin=np.min(Y_lower)),\n",
    "    go.Scatter3d(x=X_train[:,0].ravel(), y=X_train[:,1].ravel(), z=y_train.ravel(), mode='markers',\n",
    "                 marker=dict(opacity=1, size=1, color='black')),\n",
    "    go.Surface(z=Y_upper, x=X1, y=X2, cmax=np.max(Y_upper), cmin=np.min(Y_lower), showscale=True, opacity=0.8),\n",
    "    go.Surface(z=Y_lower, x=X1, y=X2, cmax=np.max(Y_upper), cmin=np.min(Y_lower), showscale=True, opacity=0.8),\n",
    "    ])\n",
    "fig.update_layout(scene = dict(\n",
    "                    xaxis_title='Depth [m]',\n",
    "                    yaxis_title='Linear Velocity [m/s]',\n",
    "                    zaxis_title='Force [N]'),\n",
    "                    width=700,\n",
    "                    margin=dict(r=20, b=10, l=10, t=10))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import savemat\n",
    "mdic = {\"depth\": X1, \"vel\": X2, \"mean\": Y, \"std\": std_mesh}\n",
    "savemat(\"model.mat\", mdic)\n",
    "mdic = {\"depth\": X_train[:,0].ravel(), \"vel\": X_train[:,1].ravel(), \"force\": y_train.ravel()}\n",
    "savemat(\"train_data.mat\", mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
