{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    " \n",
    "from scipy.signal import sosfiltfilt, butter\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'february'\n",
    "fruit = 'apple'\n",
    "fruit_labels = {'apple': 3, 'orange': 5, 'banana': 7}\n",
    "fruit_label = fruit_labels[fruit]\n",
    "cut_qualities = ['insertion']\n",
    "\n",
    "filter_data = True\n",
    "\n",
    "desired_freq = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = join('../..', 'data', 'raw_data', experiment, fruit)\n",
    "all_runs = {cq: [run for run in os.listdir(data_folder) if cq in run and run[-3:] == \"csv\"] for cq in cut_qualities}\n",
    "print(all_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(data, sensor_freq, cutoff_freq=10, order=2):\n",
    "    '''Apply digital Butterworth filter with a cutoff frequency 'cutoff_freq' and order 'order'\n",
    "    forward and backward to columns in 'data'.'''\n",
    "    sos = butter(order, cutoff_freq, fs=sensor_freq, output='sos')\n",
    "    return data.apply(lambda x: sosfiltfilt(sos, x), axis=0)\n",
    "    \n",
    "def find_extremum_backward(y, start_idx, extremum_type='min'):\n",
    "    if extremum_type not in ['max', 'min']:\n",
    "        return False\n",
    "    idx = start_idx\n",
    "    while True:\n",
    "        if extremum_type is 'min' and y.iloc[idx-1] < y.iloc[idx]:\n",
    "            idx -= 1\n",
    "        elif extremum_type is 'max' and y.iloc[idx-1] > y.iloc[idx]:\n",
    "            idx -= 1\n",
    "        else:\n",
    "            return idx\n",
    "    \n",
    "def find_extremum_forward(y, start_idx, extremum_type='min'):\n",
    "    if extremum_type not in ['max', 'min']:\n",
    "        return False\n",
    "    idx = start_idx\n",
    "    while True:\n",
    "        if extremum_type is 'min' and y.iloc[idx+1] < y.iloc[idx]:\n",
    "            idx += 1\n",
    "        elif extremum_type is 'max' and y.iloc[idx+1] > y.iloc[idx]:\n",
    "            idx += 1\n",
    "        else:\n",
    "            return idx\n",
    "\n",
    "def data_average(df):\n",
    "    '''Compute and return colum-average of data frame.'''\n",
    "    return df.mean()\n",
    "\n",
    "def middle_value(df):\n",
    "    idx = int(len(df.index) / 2)\n",
    "    return df.iloc[idx]\n",
    "    \n",
    "def downsample(data, time_vector, average_function, selected_columns):\n",
    "    '''Downsample selected columns 'selected_colums' from data frame 'data'\n",
    "    to sample points given by 'time_vecor' with a desired downsampling function 'average_function'\n",
    "    and return the downsampled data frame.'''\n",
    "    def insert_row(data, row, labels=None):\n",
    "        return data.append(pd.Series(row, labels), ignore_index=True)\n",
    "    \n",
    "    current_time_index = 0\n",
    "    downsampled_data = pd.DataFrame(columns=selected_columns)\n",
    "    \n",
    "    for i in range(len(time_vector)):\n",
    "        t = time_vector.iloc[i]\n",
    "        start_time = current_time_index\n",
    "    \n",
    "        while current_time_index < data.shape[0] and data['timestamp'].iloc[current_time_index] < t:\n",
    "            current_time_index = current_time_index + 1\n",
    "        stop_time = current_time_index\n",
    "        \n",
    "        average_data = average_function(data.iloc[start_time:stop_time][selected_columns]) if stop_time != start_time else np.empty(len(selected_columns)) * np.nan\n",
    "        downsampled_data = insert_row(downsampled_data, average_data, selected_columns)\n",
    "    \n",
    "    return downsampled_data\n",
    "\n",
    "def export_run(run, data, folder_name):\n",
    "    '''Export data from data frame 'data' to csv file.'''\n",
    "    export_folder = join('../..', 'data', folder_name)\n",
    "    \n",
    "    if not os.path.isdir(export_folder):\n",
    "        os.makedirs(export_folder)\n",
    "        \n",
    "    name = '_'.join(['segmented'] + run.split('_')[1:])\n",
    "    data.to_csv(join(export_folder, name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_headers = list(itertools.chain.from_iterable((v + '_x', v + '_y', v + '_z') for v in ['ee_force']))\n",
    "pos_headers = list(itertools.chain.from_iterable((v + '_x', v + '_y', v + '_z') for v in ['ee_pos']))\n",
    "twist_headers = list(itertools.chain.from_iterable((v + '_x', v + '_y', v + '_z') for v in ['ee_twist_lin']))\n",
    "#ft_desired_headers = ['ee_force_z']\n",
    "#twist_desired_headers = ['ee_twist_lin_z']\n",
    "desired_headers = ['timestamp'] + ft_headers + pos_headers + twist_headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def transform_velocity(df_row, headers_list):\n",
    "    R = Rotation.from_quat(df_row[['ee_ori_x', 'ee_ori_y', 'ee_ori_z', 'ee_ori_w']]).as_matrix()\n",
    "    for headers in headers_list:\n",
    "        df_row[headers] = R.dot(df_row[headers].values)\n",
    "    return df_row\n",
    "\n",
    "def get_insertion_phase(df, decision_header):\n",
    "    gradient = [(b - a) for a, b in zip(df[decision_header][:-1], df[decision_header][1:])]\n",
    "    max_index = gradient.index(max(gradient))\n",
    "    min_index = gradient.index(min(gradient))\n",
    "    if min_index > max_index:\n",
    "        min_index = gradient.index(min(gradient[:max_index]))\n",
    "    \n",
    "    phase1_start_idx = find_extremum_backward(df[decision_header], min_index, 'max')\n",
    "    phase2_start_idx = find_extremum_forward(df[decision_header], min_index, 'min')\n",
    "    phase3_start_idx = find_extremum_backward(df[decision_header], max_index, 'min')\n",
    "    phases = [0] * phase1_start_idx + [1] * (phase2_start_idx - phase1_start_idx) + \\\n",
    "             [2] * (phase3_start_idx - phase2_start_idx) + [3] * (len(df.index) - phase3_start_idx)\n",
    "    return phases\n",
    "\n",
    "def add_force_derivatives(df, headers):\n",
    "    tmp_data = df.drop(df.index[-1])\n",
    "    for header in headers:\n",
    "        tmp_data[header + '_dot'] = [(b - a) / (d - c) for a, b, c, d in \n",
    "                                     zip(df[header][:-1], df[header][1:],\n",
    "                                         df['timestamp'][:-1], df['timestamp'][1:])]\n",
    "    return tmp_data\n",
    "\n",
    "def plot_phases(data, headers, title=\"\"):\n",
    "    '''Plot data from x and y with subplots.'''\n",
    "    fig = make_subplots(rows=len(headers), cols=1,x_title='time [s]',shared_xaxes=True)\n",
    "    colors = [dict(color='blue'), dict(color='green'), dict(color='red'), dict(color='yellow')]\n",
    "    \n",
    "    for i, header in enumerate(headers):\n",
    "        for phase in range(4):\n",
    "            if i is 0:\n",
    "                fig.append_trace(go.Scatter(\n",
    "                    x=data['timestamp'][data['phase'] == phase],\n",
    "                    y=data[header][data['phase'] == phase],\n",
    "                    name='phase ' + str(phase),\n",
    "                    line=colors[phase],\n",
    "                ), row=i+1, col=1)\n",
    "            else:\n",
    "                fig.append_trace(go.Scatter(\n",
    "                    x=data['timestamp'][data['phase'] == phase],\n",
    "                    y=data[header][data['phase'] == phase],\n",
    "                    showlegend=False,\n",
    "                    line=colors[phase],\n",
    "                ), row=i+1, col=1)\n",
    "        if 'force' in header:\n",
    "            fig.update_yaxes(title_text=header + ' [N]', row=i+1, col=1)\n",
    "        elif 'twist' in header:\n",
    "            fig.update_yaxes(title_text=header + ' [m/s]', row=i+1, col=1)\n",
    "\n",
    "    fig.update_layout(height=300, width=600, title_text=title)\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "segmented_runs = {}\n",
    "for cq, runs in all_runs.items():\n",
    "    for r in runs:\n",
    "        if r in ['20210218_apple_insertion_08_0.060000_0.015000.csv',\n",
    "                 '20210218_apple_insertion_11_0.060000_0.010000.csv',\n",
    "                 '20210218_apple_insertion_17_0.060000_0.010000.csv',\n",
    "                 '20210218_banana_insertion_04_0.050000_0.010000.csv']:\n",
    "            continue\n",
    "            \n",
    "        print('Processing run ' + r)\n",
    "        all_data = pd.read_csv(join(data_folder, r))\n",
    "        \n",
    "        time_step = [(b - a) for a, b in zip(all_data['timestamp'][:-1], all_data['timestamp'][1:])]\n",
    "        if len(np.where(np.asarray(time_step) > 0.5)[0]):\n",
    "            time_step_jumps = [x[0] for x in np.where(np.asarray(time_step) > 0.5)]\n",
    "            all_data = all_data.drop(all_data.index[:time_step_jumps[0] + 1])\n",
    "            all_data = all_data.reset_index()\n",
    "        del time_step\n",
    "            \n",
    "        all_data['timestamp'] -= all_data['timestamp'].iloc[0]\n",
    "        \n",
    "        all_data = all_data.apply(lambda x: transform_velocity(x, [twist_headers]), axis=1)\n",
    "        \n",
    "        if filter_data:\n",
    "            freq = len(all_data.index) / (all_data['timestamp'].iloc[-1] - all_data['timestamp'].iloc[0])\n",
    "            all_data[ft_headers] = filter_data(all_data[ft_headers], freq, cutoff_freq=5)\n",
    "            all_data[twist_headers] = filter_data(all_data[twist_headers], freq, cutoff_freq=15)\n",
    "        del freq\n",
    "            \n",
    "        all_data = add_force_derivatives(all_data, ft_headers)\n",
    "        \n",
    "        nb_desired_samples = desired_freq * (all_data['timestamp'].iloc[-1] - all_data['timestamp'].iloc[0])\n",
    "        time_vector = pd.Series(np.linspace(all_data['timestamp'].iloc[0], all_data['timestamp'].iloc[-1], int(nb_desired_samples)))\n",
    "        data = downsample(all_data, time_vector, data_average, desired_headers)\n",
    "        damping = downsample(all_data, time_vector, middle_value, ['damping_value'])\n",
    "        data = pd.concat([data, damping], axis=1)\n",
    "        data = data.dropna()\n",
    "        \n",
    "        del all_data, damping, nb_desired_samples, time_vector\n",
    "        \n",
    "        data['label'] = [fruit_label] * len(data.index)\n",
    "        data['phase'] = get_insertion_phase(data, 'ee_force_z')\n",
    "        \n",
    "        segmented_runs[r] = data\n",
    "        \n",
    "        # uncomment if you want to plot each run seperately\n",
    "        #plot_phases(data, ['ee_force_z'])\n",
    "        #plot_phases(data, ['ee_twist_lin_z'])\n",
    "        \n",
    "        \n",
    "        # uncomment if you want to export each run seperately as csv\n",
    "        export_run(r, data, join('segmented_data', experiment, fruit))\n",
    "        del data\n",
    "        \n",
    "        #break\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
