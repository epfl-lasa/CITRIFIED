{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surgeon_recording.reader import Reader\n",
    "from glob import glob\n",
    "from os.path import join\n",
    "import os\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_average(df):\n",
    "    return df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quaternion_average(df):\n",
    "    # function taken from\n",
    "    # https://stackoverflow.com/questions/12374087/average-of-multiple-quaternions\n",
    "    A = df.transpose().dot(df)\n",
    "    w, v = np.linalg.eig(A)\n",
    "    q = v[:, w.argmax()].real\n",
    "    q = -q if q[0] < 0 else q\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(data, time_vector, average_function, selected_columns):\n",
    "    def insert_row(data, row, labels=None):\n",
    "        return data.append(pd.Series(row, labels), ignore_index=True)\n",
    "    \n",
    "    current_time_index = 0\n",
    "    downsampled_data = pd.DataFrame(columns=selected_columns)\n",
    "    \n",
    "    for i in range(len(time_vector)):\n",
    "        t = time_vector.iloc[i]\n",
    "        start_time = current_time_index\n",
    "        \n",
    "        while current_time_index < data.shape[0] and data['relative_time'].iloc[current_time_index] < t:\n",
    "            current_time_index = current_time_index + 1\n",
    "        stop_time = current_time_index\n",
    "        \n",
    "        average_data = average_function(data.iloc[start_time:stop_time][selected_columns]) if stop_time != start_time else np.zeros(len(selected_columns))\n",
    "        downsampled_data = insert_row(downsampled_data, average_data, selected_columns)\n",
    "    return downsampled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'december'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits = ['orange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_qualities = ['good'] # good / shallow / deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = ['ExactoKnife']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "force_components = ['force'] # force and/or torque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = join('..', 'data', experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders  = [join(data_folder, f, cq) for f in fruits for cq in cut_qualities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = list(itertools.chain.from_iterable([x[0] for x in os.walk(f)][1:] for f in folders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_position_header = list(itertools.chain.from_iterable((f + '_x', f + '_y', f + '_z') for f in frames))\n",
    "opt_orient_header = list(itertools.chain.from_iterable((f + '_qx', f + '_qy', f + '_qz', f + '_qw') for f in frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_desired_header = list(itertools.chain.from_iterable((v + '_x', v + '_y', v + '_z') for v in force_components))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = []\n",
    "\n",
    "for r in runs:\n",
    "    reader.play(r)\n",
    "    timestamp = reader.data['ft_sensor']['relative_time']\n",
    "    # exctract force data\n",
    "    force_data = reader.data['ft_sensor'][ft_desired_header].reset_index(drop=True)\n",
    "    # downsample optitrack data\n",
    "    opt_position_data = downsample(reader.data['optitrack'], timestamp, data_average, opt_position_header)\n",
    "    opt_orient_data = downsample(reader.data['optitrack'], timestamp, quaternion_average, opt_orient_header)\n",
    "    # merge the data\n",
    "    merge_data = pd.concat([opt_position_data, opt_orient_data, force_data], axis=1)\n",
    "    # store in the list\n",
    "    timeseries.append(merge_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "O_T_FT = np.array([[-0.0032, 1.0000, 0.0059, 0.0481],\n",
    "                   [-1.0000, -0.0031, -0.0085, 0.9708],\n",
    "                   [-0.0085, -0.0059, 0.9999, -0.3783],\n",
    "                   [0, 0, 0, 1.0000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_header =  ['opt_force_' + axis for axis in ['x', 'y', 'z']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, ts in enumerate(timeseries):\n",
    "    transform =  O_T_FT[:3, :3].dot(ts[ft_desired_header].T) + np.tile(O_T_FT[:3, 3], (len(ts),1)).T\n",
    "    timeseries[i] = pd.concat([ts, pd.DataFrame(data=transform.T, columns=transform_header)], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
