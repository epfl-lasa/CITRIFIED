Format version `v1.0`

# CITRIFIED data logging format spec

This document specifies the format for logging experimental data with the robot.

Messages will be logged in the json format. This is more verbose than "raw" logging methods
such as CSV files, but will allow much more flexibility and scalability in the data pipeline.

Each line is a separate json object, containing one or more data message fields.

```json
{"time":0.00,"metadata":{...}}
{"time":0.01,"raw":{...},"filtered":{...}}
{"time":0.02,"raw":{...},"filtered":{...}}
{"time":0.03,"esn":{...}}
```

## Defined top-level message fields

Every single message containes a `time` field, which is a relative time in seconds since recording began.
It then contains an optional number of additional message fields, which can be broadly categorized into
configuration, high frequency and low frequency types.
```json
{
  "time": 0.0,        // required, always present
  "metadata": {...},  // configuration message
  "static": {...},    // configuration message
  "raw": {...},       // high frequency message
  "filtered": {...},  // high frequency message
  "control": {...},   // high frequency message
  "model": {...},     // high frequency message
  "esn": {...}        // low frequency message
}
```
## Configuration message fields

The configuration fields contain metadata and static configurations that are not subject to change during a trial.
These fields will generally only be present in the first log line.

```json

"metadata": {
  "version": 1.0,
  "datetime": "...",
  "trial": "...", 
  "details": "...",
  "esn": {
    "inputs": [],
    "config_file": "...",
    "buffer_size": "..."
  }
},
"static": {
  "bodies": [<body_state>, ...]
}

```
- `metadata`
  - `version` - the formatting version of the log (so that parsers can be made forwards and backwards compatible)
  - `datetime` - the ISO 8601 current time using UTC timezone, for example "2021-01-23T11:22:33Z"
  - `trial` - the brief identifier code (for example, "apple_01")
  - `details` - the verbose description (the full trial yaml configuration as string)
  - `esn` 
    - `inputs` - the names of the input signals
    - `config_file` - the path of the ESN config file
    - `buffer_size` - the number of datapoints per prediction
- `static`
  - `bodies` - an array of [body states](#body-state) that define frame positions

## High frequency message fields

The high frequency fields are the main part of the log. These fields will generally be present in most log lines.
```json
"raw": {
 "bodies": [<body_state>, ...]
},
"filtered": {
  "bodies": [<body_state>, ...]
},
"control": {
 "command": <body_state>,
 "phase": "...",
},
"model": {
  "depth": 0.0,
  "gpr": {...}
}
```

- `raw` - raw continuous signals from sensors
  - `bodies` - a list of [body states](#body-state).
- `filtered` - filtered continuous signals from sensors
  - `bodies` - a list of [body states](#body-state).
- `control` - continuous control commands and discrete state signals generated by the task state machine
  - `command` - the [body state](#body-state) describing the desired twist and wrench that the DS / controller are commanding
  - `phase` - the string label for the task phase (e.g. "approach", "insertion", "cut")
- `model` - predictions or estimates for signals that are not directly measurable
  - `depth` - the heuristic estimate of contact depth, triggered by the force sensor on contact and measured as
as subsequent travel distance along the tool axis. This value is NaN or negative when not defined,
and positive when defined as inside the surface.
  - `gpr` - the prediction details of the continuous state model

## Low frequency message fields

The low frequency message is generated for and by the ESN classification.

```json
"esn": {
  "input": {"time": [], "input_0": [], "input_1": [], ...},
  "probabilities": [], 
  "class_index": 1,
  "class_name": orange
}
```

- `esn`
  - `input` - the columns of the time-window data matrix as well as the corresponding timestamp per datapoint
  - `probabilities` - the label probabilities per class as vector of legnth `#classes`
  - `class_index` - the index of the most probable class
  - `class_name` - the name of the most probable class

## Datatypes and conventions

### Task Phases
The phases of the task are the following:
- `approach`: the approach of the fruit (no contact)
- `calibration`: the calibration of the FT sensor
- `touch`: the approach of the fruit (until contact)
- `insertion`: the insertion of the fruit to a certain depth or force threshold
- `pause`: the pause between insertion and cut (if cut is desired)
- `cut`: the cut of the fruit (if desired)
- `retraction`: the removal of the knife from the fruit

### Body State
The `<body_state>` object has the form:
```json
{
  "name": "...",
  "pose": {
    "position": [x, y, z],
    "orientation": [w, x, y, z]
  },
  "twist": {
    "linear": [x, y, z],
    "angular": [x, y, z]
  },
  "wrench": {
    "force": [x, y, z],
    "torque": [x, y, z]
  },
  "frame": "..."
}
```

This object can be used to represent robot frames, optitrack objects, and even the FT sensor.

The fields `name` and `frame` relate to the name of the state and the reference frame
it is defined in. These fields are required.

The pose, twist and wrench are optional and depend on the context.
For example, the robot end-effector will likely have a pose and a twist.
The optitrack body will only have a pose, and the force-torque sensor will only have a wrench.

### Frame name conventions

- `ee` - the end-effector of the robot, NOT including tool offset
- `tool` - the tool-tip of the robot
- `robot` - the base reference frame of the principle robot
- `task` - the frame of the main object of interest (for example, the fruit frame)
- `optitrack` - the base reference frame of the optitrack setup


## Serialization

### C++
The C++ code will serialize the json log files using a header only library: https://github.com/nlohmann/json

## Deserialization

To convert the text data into data objects, it is necessary to go line by line (one timestamped message at a time).
While this is a bit tedious when most of the data is interesting as a timeseries, the benefit is that not
every message needs to be synchronous and of homogenous size, and so there is more flexibility for combining
high and low frequency data.

For each line, parse the json string into an object and check what fields are present. Then handle those
data fields accordingly - append them to a time-series object, print out the configuration metadata, plot something, etc.

### Python

```python
import json

with open('trial.json') as file:
    for line in file:
        message = json.loads(file)
        # handle message data
```

### MATLAB

```
file = fopen('trial.json');
while ~feof(file)
    line = fgetl(file);
    message = jsondecode(line);
    % handle message data
end
fclose(fid);
```


