{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surgeon_recording.reader import Reader\n",
    "from glob import glob\n",
    "from os.path import join\n",
    "import os\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from scipy.signal import filtfilt\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from scipy.spatial.transform import Rotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_average(df):\n",
    "    return df.mean()\n",
    "\n",
    "def quaternion_average(df):\n",
    "    # function taken from\n",
    "    # https://stackoverflow.com/questions/12374087/average-of-multiple-quaternions\n",
    "    A = df.transpose().dot(df)\n",
    "    w, v = np.linalg.eig(A)\n",
    "    q = v[:, w.argmax()].real\n",
    "    q = -q if q[0] < 0 else q\n",
    "    return q\n",
    "\n",
    "def downsample(data, time_vector, average_function, selected_columns):\n",
    "    def insert_row(data, row, labels=None):\n",
    "        return data.append(pd.Series(row, labels), ignore_index=True)\n",
    "    \n",
    "    current_time_index = 0\n",
    "    downsampled_data = pd.DataFrame(columns=selected_columns)\n",
    "    \n",
    "    for i in range(len(time_vector)):\n",
    "        t = time_vector.iloc[i]\n",
    "        start_time = current_time_index\n",
    "        \n",
    "        while current_time_index < data.shape[0] and data['relative_time'].iloc[current_time_index] < t:\n",
    "            current_time_index = current_time_index + 1\n",
    "        stop_time = current_time_index\n",
    "        \n",
    "        if stop_time != start_time:\n",
    "            average_data = average_function(data.iloc[start_time:stop_time][selected_columns])\n",
    "            downsampled_data = insert_row(downsampled_data, average_data, selected_columns)\n",
    "        \n",
    "    return downsampled_data\n",
    "\n",
    "def remove_offset(data, samples):\n",
    "    def get_offset(column, samples):\n",
    "        return np.sum(column.head(samples)) / float(samples)\n",
    "    corrected_data = data.apply(lambda x: x - get_offset(x, samples), axis=0)\n",
    "    return corrected_data\n",
    "\n",
    "def filter_data(data, order, a=1):\n",
    "    b = [1.0 / order] * order\n",
    "    return data.apply(lambda x: filtfilt(b, a, x), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_knife_transform(fruit_quality):\n",
    "    if fruit_quality in knife_extension:\n",
    "        extension = knife_extension[fruit_quality]\n",
    "    else:\n",
    "        extension = knife_extension[\"default\"]\n",
    "    T = np.eye(4)\n",
    "    T[2,3] = extension\n",
    "    return T\n",
    "\n",
    "def get_hom_transform(df_row, position_headers, orientation_headers):\n",
    "    T = np.eye(4)\n",
    "    T[:3,3] = df_row[position_headers]\n",
    "    T[:3,:3] = Rotation.from_quat(df_row[orientation_headers]).as_matrix()\n",
    "    return T\n",
    "\n",
    "def get_hom_transform_inv(T):\n",
    "    T_inv = np.eye(4)\n",
    "    T_inv[:3,:3] = np.transpose(T[:3,:3])\n",
    "    T_inv[:3,3] = -T_inv[:3,:3].dot(T[:3,3])\n",
    "    return T_inv\n",
    "\n",
    "def transform_data(df_row, knife_tip_T, ft_headers, position_headers, orientation_headers):\n",
    "    world_T_knife = get_hom_transform(df_row, position_headers, orientation_headers)\n",
    "    FT_T_knife = np.matmul(FT_T_world, np.matmul(world_T_knife, knife_tip_T))\n",
    "    df_row[position_headers] = FT_T_knife[:3,3]\n",
    "    df_row[orientation_headers] = Rotation.from_matrix(FT_T_knife[:3,:3]).as_quat()\n",
    "    knife_T_FT = get_hom_transform_inv(FT_T_knife)\n",
    "    \n",
    "    # correct for steepness too\n",
    "    desired_x_direction = np.cross([0,0,1], FT_T_knife[:3,2])\n",
    "    desired_x_direction = desired_x_direction / np.linalg.norm(desired_x_direction)\n",
    "    angle = np.arctan2(np.linalg.norm(np.cross(FT_T_knife[:3,0],desired_x_direction)), \n",
    "                       np.dot(FT_T_knife[:3,0],desired_x_direction))\n",
    "    if FT_T_knife[2,0] > 0:\n",
    "        angle = -angle\n",
    "    knife_T_cutting_direction = Rotation.from_euler(\"z\", angle, degrees=False).as_matrix()\n",
    "    \n",
    "    df_row[ft_headers] = np.matmul(knife_T_cutting_direction.transpose(),knife_T_FT[:3,:3]).dot(df_row[ft_headers])\n",
    "    return df_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(x, y, header=\"\"):\n",
    "    fig = make_subplots(rows=y.shape[1], cols=1,x_title='Time',)\n",
    "    \n",
    "    for index in range(y.shape[1]):\n",
    "        fig.append_trace(go.Scatter(\n",
    "            x=x,\n",
    "            y=y.iloc[:,index],\n",
    "            name=y.columns[index],\n",
    "        ), row=index+1, col=1)\n",
    "\n",
    "    fig.update_layout(height=600, width=600, title_text=header)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_data(runs, timeseries, folder_name):\n",
    "    export_folder = join('..', 'data', folder_name)\n",
    "    \n",
    "    if not os.path.isdir(export_folder):\n",
    "        os.makedirs(export_folder)\n",
    "    \n",
    "    for i, r in enumerate(runs):\n",
    "        filename = os.path.split(r)\n",
    "        name = '_'.join(filename[0].split('/')[-2:] + [filename[1]])\n",
    "        timeseries[i].to_csv(join(export_folder, name + '.csv'))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'december'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits = ['orange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_qualities = ['good'] # good / shallow / deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = ['ExactoKnife']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "force_components = ['force'] # force and/or torque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knife_extension = {\"default\": 0.003, \"banana-deep\": 0.006}\n",
    "world_T_FT = np.array([[-0.0032, 1.0000, 0.0062, 0.0527],\n",
    "                   [-1.0000, -0.0032, -0.0090, 0.9641],\n",
    "                   [-0.0090, -0.0062, 0.9999, 0.3465],\n",
    "                   [0, 0, 0, 1.0000]])\n",
    "FT_T_world = get_hom_transform_inv(world_T_FT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_sensor_offset = True\n",
    "if remove_sensor_offset:\n",
    "    samples = 40\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_force = True\n",
    "if filter_force:\n",
    "    force_filter_order = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_all = True # this will transform the force into the knife frame and the knife positions into the FT frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = join('..', 'data', 'raw_data', experiment)\n",
    "print(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders  = {cq: [join(data_folder, f, cq) for f in fruits] for cq in cut_qualities}\n",
    "print(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_runs = {cq: list(itertools.chain.from_iterable([x[0] for x in os.walk(f, followlinks=True)][1:] for f in folder)) for cq, folder in folders.items()}\n",
    "print(all_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_position_header = list(itertools.chain.from_iterable((f + '_x', f + '_y', f + '_z') for f in frames))\n",
    "opt_orient_header = list(itertools.chain.from_iterable((f + '_qx', f + '_qy', f + '_qz', f + '_qw') for f in frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_desired_header = list(itertools.chain.from_iterable((v + '_x', v + '_y', v + '_z') for v in force_components))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "timeseries = []\n",
    "\n",
    "for cq, runs in all_runs.items():\n",
    "    for r in runs:\n",
    "        print(\"Processing run \" + r)\n",
    "        reader.play(r)\n",
    "        timestamp = reader.data['ft_sensor']['relative_time']\n",
    "        timestamp.reset_index(drop= True,inplace=True)\n",
    "\n",
    "        # exctract force data\n",
    "        force_data = reader.data['ft_sensor'][ft_desired_header].reset_index(drop=True)\n",
    "        if remove_sensor_offset:\n",
    "            force_data = remove_offset(force_data, samples)\n",
    "        if filter_force:\n",
    "            force_data = filter_data(force_data, force_filter_order)\n",
    "        #plot_data(timestamp,force_data)\n",
    "\n",
    "        # downsample optitrack data\n",
    "        opt_position_data = downsample(reader.data['optitrack'], timestamp, data_average, opt_position_header)\n",
    "        opt_orient_data = downsample(reader.data['optitrack'], timestamp, quaternion_average, opt_orient_header)\n",
    "        #plot_data(timestamp, opt_position_data[opt_position_header])\n",
    "        \n",
    "        # merge the data and store\n",
    "        merge_data = pd.concat([timestamp, opt_position_data, opt_orient_data, force_data], axis=1)\n",
    "        merge_data = merge_data.dropna()\n",
    "        \n",
    "        # transform optitrack to FT frame and force to knife frame\n",
    "        if transform_all:\n",
    "            merge_data.apply(lambda x: transform_data_2(x, get_knife_transform(\"-\".join([fruits[0], cq])), \n",
    "                                                      ft_desired_header, opt_position_header, opt_orient_header), axis=1)\n",
    "        #plot_data(timestamp, merge_data[opt_position_header])\n",
    "        #plot_data(timestamp, merge_data[ft_desired_header])\n",
    "        \n",
    "        timeseries.append(merge_data)\n",
    "        \n",
    "    export_data(runs, timeseries, \"processed_transformed_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=3, cols=1,x_title='time [s]')\n",
    "fig1 = make_subplots(rows=3, cols=1,x_title='time [s]')\n",
    "fig2 = make_subplots(rows=3, cols=1,x_title='relative displacement from cut start [m]')\n",
    "\n",
    "timeseries2 = [] \n",
    "merge_data2 = pd.DataFrame()\n",
    "\n",
    "for i, r in enumerate(runs):\n",
    "    gradient = [(b - a) for a, b in\n",
    "                        zip(timeseries[i][\"force_x\"][:-1], timeseries[i][\"force_x\"][1:])]\n",
    "    max_index = gradient.index(max(gradient))\n",
    "    min_index = gradient.index(min(gradient))\n",
    "    ignore_edges_length = 0\n",
    "    data_segmented = timeseries[i].loc[max_index + ignore_edges_length:min_index - ignore_edges_length]\n",
    "    data_segmented.reset_index(inplace=True)\n",
    "    \n",
    "    total_time = data_segmented[\"relative_time\"].iloc[-1] - data_segmented.loc[0, \"relative_time\"]\n",
    "    data_segmented.loc[:, \"relative_time\"] = (data_segmented[\"relative_time\"] -\n",
    "                                                      data_segmented.loc[\n",
    "                                                          0, \"relative_time\"]) / total_time * 5\n",
    "    \n",
    "    for column in opt_position_header:\n",
    "        data_segmented.loc[:, column] -= data_segmented.loc[0, column]\n",
    "    \n",
    "    #plot_data(data_segmented[\"relative_time\"], data_segmented[ft_desired_header])\n",
    "    #plot_data(data_segmented[\"relative_time\"], data_segmented[opt_position_header])\n",
    "    \n",
    "    angle = np.arctan(data_segmented[\"ExactoKnife_x\"].iloc[-20] / data_segmented[\"ExactoKnife_y\"].iloc[-20])\n",
    "    R = Rotation.from_euler(\"z\", angle).as_matrix()\n",
    "    data_segmented.loc[:, \"ExactoKnife_x\"] = [(R.dot(x))[0] for x in\n",
    "                                              zip(data_segmented[\"ExactoKnife_x\"],\n",
    "                                                  data_segmented[\"ExactoKnife_y\"],\n",
    "                                                  data_segmented[\"ExactoKnife_z\"])]\n",
    "    data_segmented.loc[:, \"ExactoKnife_y\"] = [(R.dot(x))[1] for x in\n",
    "                                              zip(data_segmented[\"ExactoKnife_x\"],\n",
    "                                                  data_segmented[\"ExactoKnife_y\"],\n",
    "                                                  data_segmented[\"ExactoKnife_z\"])]\n",
    "    \n",
    "    for i, pos in enumerate(opt_position_header):\n",
    "        fig.append_trace(go.Scatter(\n",
    "                x=data_segmented[\"relative_time\"],\n",
    "                y=data_segmented[pos],\n",
    "                ), row=i+1, col=1)\n",
    "    for i, force in enumerate(ft_desired_header):\n",
    "        fig1.append_trace(go.Scatter(\n",
    "                x=data_segmented[\"relative_time\"],\n",
    "                y=data_segmented[force],\n",
    "                ), row=i+1, col=1)\n",
    "        \n",
    "    displacement = [np.linalg.norm(x) for x in\n",
    "                            zip(data_segmented[\"ExactoKnife_x\"], data_segmented[\"ExactoKnife_y\"],\n",
    "                                data_segmented[\"ExactoKnife_z\"])]\n",
    "    \n",
    "    data_segmented[\"displacement\"] = displacement\n",
    "    timeseries2.append(data_segmented)\n",
    "    \n",
    "    for i, force in enumerate(ft_desired_header):\n",
    "        fig2.append_trace(go.Scatter(\n",
    "                x=displacement,\n",
    "                y=data_segmented[force],\n",
    "                mode='markers',\n",
    "                showlegend=False,\n",
    "                ), row=i+1, col=1)\n",
    "        \n",
    "    #merge_data2 = pd.concat([merge_data2, data_segmented], axis=0)\n",
    "\n",
    "#print(merge_data2)\n",
    "        \n",
    "export_data(runs, timeseries2, \"segmented_data\")\n",
    "#export_data(runs, [merge_data2], \"concat_data\")\n",
    "\n",
    "model_x = pd.read_csv(join(data_folder,\"model_x.csv\"), names=[\"dis\",\"y\",\"y+\",\"y-\"])\n",
    "model_y = pd.read_csv(join(data_folder,\"model_y.csv\"), names=[\"dis\",\"y\",\"y+\",\"y-\"])\n",
    "model_z = pd.read_csv(join(data_folder,\"model_z.csv\"), names=[\"dis\",\"y\",\"y+\",\"y-\"])\n",
    "\n",
    "\n",
    "\n",
    "fig.update_yaxes(title_text=\"position_x [m]\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"position_y [m]\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"position_z [m]\", row=3, col=1)\n",
    "fig.update_layout(height=600, width=800, title_text='-'.join([fruits[0],cut_qualities[0]]),showlegend=False)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "fig1.update_yaxes(title_text=\"force_x [N]\", row=1, col=1)\n",
    "fig1.update_yaxes(title_text=\"force_y [N]\", row=2, col=1)\n",
    "fig1.update_yaxes(title_text=\"force_z [N]\", row=3, col=1)\n",
    "fig1.update_layout(height=600, width=800, title_text='-'.join([fruits[0],cut_qualities[0]]),showlegend=False)\n",
    "fig1.show()\n",
    "\n",
    "for i, model in enumerate([model_x]):\n",
    "    fig2.append_trace(go.Scatter(\n",
    "                    x=model[\"dis\"],\n",
    "                    y=model[\"y\"],\n",
    "                    line=dict(color='rgb(0,0,0)', width=3),\n",
    "                    name=\"y_predicted\",\n",
    "                    ), row=i+1, col=1)\n",
    "\n",
    "    fig2.append_trace(go.Scatter(\n",
    "                    x=model[\"dis\"],\n",
    "                    y=model[\"y+\"],\n",
    "                    line=dict(color='rgb(255,0,0)', width=3),\n",
    "                    name=\"y_predicted + variance\",\n",
    "                    ), row=i+1, col=1)\n",
    "\n",
    "    fig2.append_trace(go.Scatter(\n",
    "                    x=model[\"dis\"],\n",
    "                    y=model[\"y-\"],\n",
    "                    line=dict(color='rgb(255,0,0)', width=3),\n",
    "                    name=\"y_predicted - variance\",\n",
    "                    ), row=i+1, col=1)\n",
    "\n",
    "for i, model in enumerate([model_y, model_z]):\n",
    "    fig2.append_trace(go.Scatter(\n",
    "                    x=model[\"dis\"],\n",
    "                    y=model[\"y\"],\n",
    "                    line=dict(color='rgb(0,0,0)', width=3),\n",
    "                    showlegend=False,\n",
    "                    ), row=i+2, col=1)\n",
    "\n",
    "    fig2.append_trace(go.Scatter(\n",
    "                    x=model[\"dis\"],\n",
    "                    y=model[\"y+\"],\n",
    "                    line=dict(color='rgb(255,0,0)', width=3),\n",
    "                    showlegend=False,\n",
    "                    ), row=i+2, col=1)\n",
    "\n",
    "    fig2.append_trace(go.Scatter(\n",
    "                    x=model[\"dis\"],\n",
    "                    y=model[\"y-\"],\n",
    "                    line=dict(color='rgb(255,0,0)', width=3),\n",
    "                    showlegend=False,\n",
    "                    ), row=i+2, col=1)\n",
    "\n",
    "fig2.update_yaxes(title_text=\"force_x [N]\", row=1, col=1)\n",
    "fig2.update_yaxes(title_text=\"force_y [N]\", row=2, col=1)\n",
    "fig2.update_yaxes(title_text=\"force_z [N]\", row=3, col=1)\n",
    "fig2.update_layout(height=800, width=1000, title_text='-'.join([fruits[0],cut_qualities[0]]))\n",
    "fig2.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(export_folder):\n",
    "    os.makedirs(export_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, r in enumerate(runs):\n",
    "    filename = os.path.split(r)\n",
    "    name = '_'.join(filename[0].split('/')[-2:] + [filename[1]])\n",
    "    timeseries[i].to_csv(join(export_folder, name + '.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
