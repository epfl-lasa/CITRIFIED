{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    " \n",
    "from scipy.signal import sosfiltfilt, butter\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'february'\n",
    "fruit = 'apple'\n",
    "fruit_labels = {'apple': 3, 'orange': 5, 'banana': 7}\n",
    "fruit_label = fruit_labels[fruit]\n",
    "cut_qualities = ['insertion']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = join('../..', 'data', 'raw_data', experiment, fruit)\n",
    "all_runs = {cq: [run for run in os.listdir(data_folder) if cq in run and run[-3:] == \"csv\"] for cq in cut_qualities}\n",
    "print(all_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_headers = list(itertools.chain.from_iterable((v + '_x', v + '_y', v + '_z') for v in ['ee_force']))\n",
    "pos_headers = list(itertools.chain.from_iterable((v + '_x', v + '_y', v + '_z') for v in ['ee_pos']))\n",
    "twist_headers = list(itertools.chain.from_iterable((v + '_x', v + '_y', v + '_z') for v in ['ee_twist_lin']))\n",
    "desired_headers = ['timestamp'] + ft_headers + pos_headers + twist_headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def transform_velocity(df_row, headers_list):\n",
    "    R = Rotation.from_quat(df_row[['ee_ori_x', 'ee_ori_y', 'ee_ori_z', 'ee_ori_w']]).as_matrix()\n",
    "    for headers in headers_list:\n",
    "        df_row[headers] = R.dot(df_row[headers].values)\n",
    "    return df_row\n",
    "\n",
    "def find_extremum_backward(y, start_idx, extremum_type='min'):\n",
    "    if extremum_type not in ['max', 'min']:\n",
    "        return False\n",
    "    idx = start_idx\n",
    "    while True:\n",
    "        if extremum_type is 'min' and y.iloc[idx-1] < y.iloc[idx]:\n",
    "            idx -= 1\n",
    "        elif extremum_type is 'max' and y.iloc[idx-1] > y.iloc[idx]:\n",
    "            idx -= 1\n",
    "        else:\n",
    "            return idx\n",
    "    \n",
    "def find_extremum_forward(y, start_idx, extremum_type='min'):\n",
    "    if extremum_type not in ['max', 'min']:\n",
    "        return False\n",
    "    idx = start_idx\n",
    "    while True:\n",
    "        if extremum_type is 'min' and y.iloc[idx+1] < y.iloc[idx]:\n",
    "            idx += 1\n",
    "        elif extremum_type is 'max' and y.iloc[idx+1] > y.iloc[idx]:\n",
    "            idx += 1\n",
    "        else:\n",
    "            return idx\n",
    "        \n",
    "\n",
    "def filter_data(data, sensor_freq, cutoff_freq=10, order=2):\n",
    "    '''Apply digital Butterworth filter with a cutoff frequency 'cutoff_freq' and order 'order'\n",
    "    forward and backward to columns in 'data'.'''\n",
    "    sos = butter(order, cutoff_freq, fs=sensor_freq, output='sos')\n",
    "    return data.apply(lambda x: sosfiltfilt(sos, x), axis=0)\n",
    "\n",
    "def get_insertion_phase(df, decision_header):\n",
    "    freq = len(df.index) / (df['timestamp'].iloc[-1] - df['timestamp'].iloc[0])\n",
    "    force = filter_data(df[ft_headers], freq, cutoff_freq=8)\n",
    "    gradient = [(b - a) for a, b in zip(force[decision_header][:-1], force[decision_header][1:])]\n",
    "    max_index = gradient.index(max(gradient))\n",
    "    min_index = gradient.index(min(gradient))\n",
    "    if min_index > max_index:\n",
    "        min_index = gradient.index(min(gradient[:max_index]))\n",
    "    \n",
    "    phase1_start_idx = find_extremum_backward(force[decision_header], min_index, 'max')\n",
    "    phase2_start_idx = find_extremum_forward(force[decision_header], min_index, 'min')\n",
    "    phase3_start_idx = find_extremum_backward(force[decision_header], max_index, 'min')\n",
    "    phases = [0] * phase1_start_idx + [1] * (phase2_start_idx - phase1_start_idx) + \\\n",
    "             [2] * (phase3_start_idx - phase2_start_idx) + [3] * (len(force.index) - phase3_start_idx)\n",
    "    return phases\n",
    "\n",
    "\n",
    "def plot_phases(data, headers, title=\"\"):\n",
    "    '''Plot data from x and y with subplots.'''\n",
    "    fig = make_subplots(rows=len(headers), cols=1,x_title='time [s]',shared_xaxes=True)\n",
    "    colors = [dict(color='blue'), dict(color='green'), dict(color='red'), dict(color='yellow')]\n",
    "    \n",
    "    for i, header in enumerate(headers):\n",
    "        for phase in range(4):\n",
    "            if i is 0:\n",
    "                fig.append_trace(go.Scatter(\n",
    "                    x=data['timestamp'][data['phase'] == phase],\n",
    "                    y=data[header][data['phase'] == phase],\n",
    "                    name='phase ' + str(phase),\n",
    "                    line=colors[phase],\n",
    "                ), row=i+1, col=1)\n",
    "            else:\n",
    "                fig.append_trace(go.Scatter(\n",
    "                    x=data['timestamp'][data['phase'] == phase],\n",
    "                    y=data[header][data['phase'] == phase],\n",
    "                    showlegend=False,\n",
    "                    line=colors[phase],\n",
    "                ), row=i+1, col=1)\n",
    "        if 'force' in header:\n",
    "            fig.update_yaxes(title_text=header + ' [N]', row=i+1, col=1)\n",
    "        elif 'twist' in header:\n",
    "            fig.update_yaxes(title_text=header + ' [m/s]', row=i+1, col=1)\n",
    "\n",
    "    fig.update_layout(height=300, width=600, title_text=title)\n",
    "    fig.show()\n",
    "    \n",
    "def export_run(run, data, folder_name):\n",
    "    '''Export data from data frame 'data' to csv file.'''\n",
    "    export_folder = join('../..', 'data', folder_name)\n",
    "    \n",
    "    if not os.path.isdir(export_folder):\n",
    "        os.makedirs(export_folder)\n",
    "        \n",
    "    name = '_'.join(['segmented'] + run.split('_')[1:])\n",
    "    data.to_csv(join(export_folder, name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "segmented_runs = {}\n",
    "for cq, runs in all_runs.items():\n",
    "    for r in runs:\n",
    "        if r in ['20210218_apple_insertion_08_0.060000_0.015000.csv',\n",
    "                 '20210218_apple_insertion_11_0.060000_0.010000.csv',\n",
    "                 '20210218_apple_insertion_17_0.060000_0.010000.csv',\n",
    "                 '20210218_banana_insertion_04_0.050000_0.010000.csv',\n",
    "                 '20210218_orange_insertion_07_0.050000_0.015000.csv',\n",
    "                 '20210218_orange_insertion_23_0.070000_0.015000.csv']:\n",
    "            continue\n",
    "            \n",
    "        print('Processing run ' + r)\n",
    "        all_data = pd.read_csv(join(data_folder, r))\n",
    "        \n",
    "        time_step = [(b - a) for a, b in zip(all_data['timestamp'][:-1], all_data['timestamp'][1:])]\n",
    "        if len(np.where(np.asarray(time_step) > 0.5)[0]):\n",
    "            time_step_jumps = [x[0] for x in np.where(np.asarray(time_step) > 0.5)]\n",
    "            all_data = all_data.drop(all_data.index[:time_step_jumps[0] + 1])\n",
    "            all_data = all_data.reset_index()\n",
    "        del time_step\n",
    "            \n",
    "        all_data['timestamp'] -= all_data['timestamp'].iloc[0]\n",
    "        \n",
    "        all_data = all_data.apply(lambda x: transform_velocity(x, [twist_headers]), axis=1)\n",
    "        data = all_data[desired_headers]\n",
    "        data['label'] = [fruit_label] * len(data.index)\n",
    "        data['phase'] = get_insertion_phase(data, 'ee_force_z')\n",
    "        \n",
    "        segmented_runs[r] = data\n",
    "        \n",
    "        # uncomment if you want to plot each run seperately\n",
    "        #plot_phases(data, ['ee_force_z'])\n",
    "        #plot_phases(data, ['ee_pos_z'])\n",
    "        \n",
    "        # uncomment if you want to export each run seperately as csv\n",
    "        export_run(r, data, join('labeled_raw_data', experiment, fruit))\n",
    "        del all_data, data\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
